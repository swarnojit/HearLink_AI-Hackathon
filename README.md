

# ğŸ§ HearLink â€“ Bridging Educational Gaps with AI

> **Empowering Specially-Abled & General Students with AI-Powered Inclusive Education Tools**  
> *Built with â¤ï¸ for hearing & speech-impaired learners, inclusive classrooms & empathetic educators.*

---

![image](https://github.com/user-attachments/assets/c257ea4e-d522-45a0-b81c-286b9650d146)


## ğŸš€ Overview

**HearLink** is an AI-powered educational assistant that brings accessibility, inclusivity, and personalization to the classroom. Itâ€™s specially designed to help hearing and speech-impaired students while also offering features beneficial for general students and teachers.

By leveraging real-time speech-to-text, facial emotion recognition, and AI-generated learning content, HearLink transforms any class into an engaging and inclusive experience.

---

## ğŸ§  Problem We're Solving

> ğŸ“š Lack of real-time assistive tools for communication  
> ğŸ”‡ Difficulty understanding spoken content without lip reading  
> ğŸ˜• No visibility into student emotional engagement  
> ğŸš« No unified platform for accessibility, personalization & insights  

---

## âœ¨ Key Features

| ğŸ‘¨â€ğŸ“ For Students | ğŸ‘©â€ğŸ« For Teachers |
|------------------|-------------------|
| ğŸ—£ï¸ Real-time Speech-to-Text | ğŸ“Š Emotion Detection + Engagement Insights |
| ğŸŒ Multilingual & Offline Support | ğŸ“ˆ Analytics Dashboard |
| ğŸ“‹ Personalized Notes, Flashcards & Quizzes | ğŸ§  Personalized Feedback for Each Student |
| ğŸ“± Web Platform with Responsive UI | ğŸ“‘ Reports & Class-wise Trends |

---

## ğŸ‘¥ Target Users

- ğŸ§â€â™‚ï¸ **Specially-Abled Students**: Speech-to-text transcription for easier access to lectures
- ğŸ“ **General Students**: Personalized AI-generated notes and study materials
- ğŸ‘©â€ğŸ« **Teachers**: Live emotion tracking and dashboards for performance feedback

---

## ğŸ› ï¸ Tech Stack

### ğŸ§© Frontend
- `HTML`, `CSS`, `JavaScript`
- Responsive, accessible design

### ğŸ”§ Backend
- `Python`
- `Flask` (API + Routing)
- `SQLAlchemy` (Database ORM)

### ğŸ§  Machine Learning & AI
| Task | Technology |
|------|------------|
| Speech-to-Text | `Whisper` by OpenAI |
| Emotion Detection | `DeepFace`, `OpenCV`, `PyTorch` |
| NLP / Quiz Generation | `Google Gemini`, `Ollama` |
| Computer Vision | `OpenCV` | |

---

## ğŸ§ª Datasets Used

| Type | Datasets |
|------|----------|
| ğŸ”Š Speech | `LibriSpeech`, `Mozilla Common Voice` |
| ğŸ˜Š Emotion | `FER-2013`, `AffectNet`, `RAF-DB` |
| ğŸ§¾ NLP | `DailyDialog`, `SQuAD`, `Tatoeba` |
| ğŸ¥ User-Generated | Classroom audio/video, real-time student data |
| ğŸ§¬ Synthetic | Augmented data for robustness |

---

## ğŸ“ˆ Success Criteria

| Metric | Goal |
|--------|------|
| ğŸ—£ï¸ Transcription Accuracy | â‰¥ 85% (Multilingual) |
| ğŸ˜ Emotion Recognition Accuracy | â‰¥ 80% |
| ğŸ“š Quiz/Notes Usage | Used by â‰¥ 3 students during demo |
| ğŸ“‰ Improved Engagement | Actionable feedback adopted by teachers |
| ğŸ“¡ Offline Usability | Core features available without internet |

---

## ğŸ—ƒï¸ System Architecture

```plaintext
Input Layer
â†’ Audio (Mic) / Video (Camera Feed)

â†“
Processing Layer
â†’ Speech-to-Text (Whisper)
â†’ Emotion Detection (DeepFace + OpenCV)
â†’ NLP (Gemini, Ollama)
â†’ Vector Storage (FAISS / ChromaDB)

â†“
Application Layer
â†’ Study Materials Generator
â†’ Teacher Dashboard with Engagement Trends

â†“
Interface Layer
â†’ Frontend (HTML/CSS/JS)
â†’ Flask API for ML & DB handling
```

---

## ğŸ›°ï¸ Cloud vs On-Device Mode

| Mode | Details |
|------|---------|
| **Cloud (Default)** | Google Cloud Run, Whisper API, Serverless |
| **Offline (Fallback)** | Whisper Tiny, Emotion models locally on device |
| **Smart Sync** | Cache locally, sync when connected |
| **On-Device (Planned)** | Lightweight summary & emotion alerts on mobile |

---

## ğŸŒ Accessibility Highlights

- ğŸ§ Icon-based navigation for low-literacy users
- ğŸŒ Multilingual support across UI and content
- ğŸ“¡ Offline fallback for rural areas
- ğŸ” Privacy-first with user consent & explainability

---

## ğŸ“¦ Modular & Scalable Design

- ğŸ”Œ Plug-and-play modules: Use STT, Emotion Detection, or Quiz Gen independently
- ğŸ§ª Open-source and community extensible
- ğŸ“± Works on phones, tablets, desktops
- ğŸ§  Localized and scalable across regions

---

## ğŸ”— Key Resources

- ğŸ§  **GitHub Repo:** [HearLink](https://github.com/swarnojit/HearLink_AI-Hackathon)  


---

## ğŸ”® Upcoming Enhancements

- ğŸ“± Native Mobile App (React Native)
- ğŸ“· Emotion Overlay on Video Feed
- ğŸ§  Adaptive Quizzes based on real-time emotion
- ğŸ”— Blockchain integration for learning logs (planned)

---

## ğŸ¤ Team

**ğŸ‘¨â€ğŸ’» Team Name:** HearLink  
**ğŸ§  Team Lead:** Swarnojit Maitra  
**Team Members:**  PriyaDeep Mullick I  Arpan Chowdhury I Mayukh Bhowmik

**ğŸ« Domain:** Education & Accessibility  



